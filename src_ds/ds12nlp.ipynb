{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 自然言語処理にむけて\n",
    "\n",
    "画像認識は、もともと画像データが多次元ベクトルで表現されており、\n",
    "よく似た画像が近いベクトルで表現されるなど、機械学習で処理しやすい前提が整っていました。\n",
    "一方、自然言語などのテキストは、文字コードが近くても意味が近いわけではありません。\n",
    "自然言語を機械学習で処理するためには、\n",
    "テキストの特徴量を多次元ベクトルでうまく表現することが鍵になります。\n",
    "\n",
    "最後のまとめとして、\n",
    "自然言語処理を機械学習で扱う方法を考えていきましょう。\n",
    "\n",
    "__モジュールの準備__\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import japanize_matplotlib #matplotlibの日本語化  \n",
    "except ModuleNotFoundError:\n",
    "    !pip install japanize_matplotlib\n",
    "    import japanize_matplotlib \n",
    "sns.set(font=\"IPAexGothic\") #日本語フォント設定\n"
   ]
  },
  {
   "source": [
    "## 形態素解析\n",
    "\n",
    "言語における意味の基本単位は語 (word) です。まず、語を取り出す方法からみていきましょう。\n",
    "\n",
    "### 英語と日本語\n",
    "\n",
    "自然言語処理は、言語の種類によって難しさや扱い方が異なります。\n",
    "\n",
    "* (英語文) I bought a book \n",
    "* (日本語文) 私は本を買った\n",
    "\n",
    "英語は、空白で区切られたものを語と考えることができます。\n",
    "したがって、Python の標準文字列ライブラリだけで、簡単に語を取り出すことができます。\n",
    "\n",
    "__英語の字句解析__"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['I', 'bought', 'a', 'book']"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "s = \"I bought a book\"\n",
    "s.split()"
   ]
  },
  {
   "source": [
    "日本語では、まず語の区切りを判定する必要があります。\n",
    "しかし、この語の区切りを判定するのが かなりの難処理です。\n",
    "この難処理を行ってくれるのが**形態素解析ライブラリ**です。\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### spaCy/GINZA\n",
    "\n",
    "spaCy は、Explosion AI 社の開発するオープンソースの自然言語処理ライブラリです。2019 年に、 リクルート AI 研究所と国立言語研究所の研究成果である GiNZA が登場し、実用的な日本語処理が 手軽に利用できるようになりました。\n",
    "\n",
    "まずは、GiNZA の導入から始めましょう。`pip install ginza` を入力するだけで、 spaCy を含めて、自然言語処理に必要なライブラリがまとめてインストールされます。\n",
    "\n",
    "```\n",
    "!pip install ginza\n",
    "import pkg_resources, imp\n",
    "imp.reload(pkg_resources)\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 私 私 PRON 代名詞\n1 は は ADP 助詞-係助詞\n2 本 本 NOUN 名詞-普通名詞-一般\n3 を を ADP 助詞-格助詞\n4 買っ 買う VERB 動詞-一般\n5 た た AUX 助動詞\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('ja_ginza') \n",
    "\n",
    "doc = nlp(\"私は本を買った\") #形態素解析\n",
    "for word in doc:\n",
    "    print(word.i, word.orth_, word.lemma_, word.pos_, word.tag_)"
   ]
  },
  {
   "source": [
    "日本語文を単語単位に分割する関数を定義しておきましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['私', 'は', '本', 'を', '買う', 'た']\n"
     ]
    }
   ],
   "source": [
    "def wakachi(s):\n",
    "    doc = nlp(s)\n",
    "    return [word.lemma_ for word in doc]  # word.lemma_ は標準形\n",
    "\n",
    "print(wakachi('私は本を買った'))\n"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Let's try\n",
    "\n",
    "自然言語処理と形態素解析の良い練習問題は、「自然言語処理１００本ノック」にあります。\n",
    "\n",
    "http://www.cl.ecei.tohoku.ac.jp/nlp100/\n",
    "\n",
    "Web上には、解説記事がたくさん掲載されていますので、参考にしながら解いてみると実力がつきます。\n",
    "\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## アンケート分析\n",
    "\n",
    "不動産屋による「まちづくりに関するアンケート」に基づいて、アンケート解析を試していきましょう。\n",
    "アンケードには、アンケートの回答日、コメント自由記述形式、満足度(5段階評価: 1 不満 - 5 満足)が記載されています。\n",
    "\n",
    "__データの取り寄せ__\n",
    "\n",
    "本データは、下山らによる「Python 実践データ分析 100 本ノック」から講義用に編集したも のを使っています。\n",
    "\n",
    "```\n",
    "!wget https://KuramitsuLab.github.io/data/survey.csv\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          日付              コメント  満足度\n",
       "0  2019/3/11      駅前に若者が集まっている    1\n",
       "1  2019/2/25  スポーツできる場所があるのが良い    5\n",
       "2  2019/2/18         子育て支援が嬉しい    5\n",
       "3   2019/4/9   保育園に入れる（待機児童なし）    4\n",
       "4   2019/1/6         駅前商店街が寂しい    2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>日付</th>\n      <th>コメント</th>\n      <th>満足度</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019/3/11</td>\n      <td>駅前に若者が集まっている</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019/2/25</td>\n      <td>スポーツできる場所があるのが良い</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019/2/18</td>\n      <td>子育て支援が嬉しい</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019/4/9</td>\n      <td>保育園に入れる（待機児童なし）</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019/1/6</td>\n      <td>駅前商店街が寂しい</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "data = pd.read_csv(\"survey.csv\")\n",
    "data.head() #最初の5行を表示"
   ]
  },
  {
   "source": [
    "### コメントを眺める \n",
    "\n",
    "今まで、様々なデータを扱ってきましたが、\n",
    "今回のデータは、自由記述形式のテキストが入っているのが特徴です。\n",
    "\n",
    "まず、アンケート中のコメントの分量を把握してみましょう。\n",
    "文字数を数えて、新しいカラム(`文字数`)を作って格納します。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"文字数\"] = data[\"コメント\"].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([12., 24., 22., 10.,  6.,  6.,  5.,  0.,  0.,  1.]),\n",
       " array([ 4. ,  8.6, 13.2, 17.8, 22.4, 27. , 31.6, 36.2, 40.8, 45.4, 50. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"254.063817pt\" version=\"1.1\" viewBox=\"0 0 372.556562 254.063817\" width=\"372.556562pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-19T18:14:25.243725</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 254.063817 \nL 372.556562 254.063817 \nL 372.556562 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.556563 227.034129 \nL 365.356562 227.034129 \nL 365.356562 9.594129 \nL 30.556563 9.594129 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 85.474349 227.034129 \nL 85.474349 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- 10 -->\n      <g style=\"fill:#262626;\" transform=\"translate(78.546068 244.773817)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 38.484375 0.984375 \nL 29.6875 0.984375 \nL 29.6875 64.109375 \nQ 21.4375 61.28125 12.3125 59.328125 \nL 10.6875 66.109375 \nQ 23.734375 69.390625 32.90625 73.921875 \nL 38.484375 73.921875 \nz\n\" id=\"IPAexGothic-49\"/>\n        <path d=\"M 31.84375 73.828125 \nQ 45.015625 73.828125 52.09375 61.625 \nQ 57.71875 51.953125 57.71875 36.625 \nQ 57.71875 21.4375 52.09375 11.578125 \nQ 45.125 -0.484375 31.5 -0.484375 \nQ 17.921875 -0.484375 10.9375 11.578125 \nQ 5.328125 21.4375 5.328125 36.71875 \nQ 5.328125 58.015625 15.625 67.71875 \nQ 22.171875 73.828125 31.84375 73.828125 \nz\nM 31.5 66.65625 \nQ 23.6875 66.65625 19.1875 58.734375 \nQ 14.59375 50.734375 14.59375 36.625 \nQ 14.59375 22.75 19.09375 14.796875 \nQ 23.640625 6.984375 31.5 6.984375 \nQ 40.921875 6.984375 45.453125 18.015625 \nQ 48.4375 25.34375 48.4375 37.109375 \nQ 48.4375 50.875 43.84375 58.734375 \nQ 39.203125 66.65625 31.5 66.65625 \nz\n\" id=\"IPAexGothic-48\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-49\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 151.640357 227.034129 \nL 151.640357 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g style=\"fill:#262626;\" transform=\"translate(144.712076 244.773817)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 57.171875 0.984375 \nL 6.984375 0.984375 \nL 6.984375 9.28125 \nQ 12.890625 23.046875 29.59375 34.421875 \nL 32.375 36.28125 \nQ 40.921875 42.140625 43.609375 45.40625 \nQ 46.6875 49.265625 46.6875 53.8125 \nQ 46.6875 58.9375 43.0625 62.546875 \nQ 39.0625 66.546875 32.5625 66.546875 \nQ 19.53125 66.546875 15.484375 52 \nL 7.765625 54.78125 \nQ 13.328125 73.828125 33.0625 73.828125 \nQ 43.84375 73.828125 50.25 67.4375 \nQ 55.859375 61.671875 55.859375 53.515625 \nQ 55.859375 47.46875 52.25 42.53125 \nQ 48.921875 37.75 36.96875 30.28125 \nL 34.859375 29 \nQ 19.625 19.578125 15.28125 8.890625 \nL 57.171875 8.890625 \nz\n\" id=\"IPAexGothic-50\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-50\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 217.806365 227.034129 \nL 217.806365 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- 30 -->\n      <g style=\"fill:#262626;\" transform=\"translate(210.878084 244.773817)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 37.203125 37.796875 \nQ 54.78125 34.625 54.78125 19.96875 \nQ 54.78125 11.1875 48.875 5.5625 \nQ 42.328125 -0.484375 30.375 -0.484375 \nQ 12.453125 -0.484375 4.5 13.765625 \nL 11.8125 17.671875 \nQ 17.328125 6.890625 30.28125 6.890625 \nQ 37.890625 6.890625 42.09375 10.796875 \nQ 46.09375 14.5 46.09375 20.171875 \nQ 46.09375 26.859375 40.09375 30.90625 \nQ 34.625 34.578125 25.6875 34.578125 \nL 21.296875 34.578125 \nL 21.296875 41.703125 \nL 25.875 41.703125 \nQ 34.859375 41.703125 39.59375 45.125 \nQ 44.671875 48.734375 44.671875 54.828125 \nQ 44.671875 61.46875 38.96875 64.65625 \nQ 35.296875 66.84375 30.171875 66.84375 \nQ 19.34375 66.84375 14.109375 55.90625 \nL 6.78125 59.421875 \nQ 14.015625 73.828125 30.28125 73.828125 \nQ 40.578125 73.828125 46.96875 68.65625 \nQ 53.375 63.578125 53.375 55.21875 \nQ 53.375 47.3125 47.171875 42.28125 \nQ 43.171875 39.0625 37.203125 38.1875 \nz\n\" id=\"IPAexGothic-51\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-51\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 283.972373 227.034129 \nL 283.972373 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- 40 -->\n      <g style=\"fill:#262626;\" transform=\"translate(277.044092 244.773817)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 59.578125 18.109375 \nL 47.796875 18.109375 \nL 47.796875 0.984375 \nL 39.796875 0.984375 \nL 39.796875 18.109375 \nL 3.078125 18.109375 \nL 3.078125 26.125 \nL 38.375 73.09375 \nL 47.796875 73.09375 \nL 47.796875 25.53125 \nL 59.578125 25.53125 \nz\nM 40.28125 64.203125 \nL 39.984375 64.203125 \nQ 35.59375 57.125 31.296875 51.3125 \nL 11.859375 25.53125 \nL 39.796875 25.53125 \nL 39.796875 49.125 \nQ 39.796875 54.390625 40.28125 64.203125 \nz\n\" id=\"IPAexGothic-52\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-52\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 350.138381 227.034129 \nL 350.138381 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 50 -->\n      <g style=\"fill:#262626;\" transform=\"translate(343.210099 244.773817)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 18.40625 40.671875 \nQ 25.53125 46.296875 33.9375 46.296875 \nQ 44 46.296875 50.640625 39.5 \nQ 56.84375 33.015625 56.84375 23.390625 \nQ 56.84375 14.65625 51.515625 8.015625 \nQ 44.828125 -0.484375 31.734375 -0.484375 \nQ 14.984375 -0.484375 7.328125 12.25 \nL 14.65625 16.0625 \nQ 20.453125 6.78125 31.453125 6.78125 \nQ 38.53125 6.78125 43.265625 11.1875 \nQ 48.140625 15.828125 48.140625 23.484375 \nQ 48.140625 30.71875 43.84375 35.015625 \nQ 39.359375 39.5 32.125 39.5 \nQ 21.96875 39.5 16.75 31.6875 \nL 9.234375 32.671875 \nL 13.8125 72.40625 \nL 53.21875 72.40625 \nL 53.21875 64.890625 \nL 20.953125 64.890625 \nL 17.71875 40.671875 \nz\n\" id=\"IPAexGothic-53\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-53\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 30.556563 227.034129 \nL 365.356562 227.034129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(14.128281 231.153973)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 30.556563 183.891272 \nL 365.356562 183.891272 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5 -->\n      <g style=\"fill:#262626;\" transform=\"translate(14.128281 188.011116)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 30.556563 140.748415 \nL 365.356562 140.748415 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 10 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 144.868259)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-49\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 30.556563 97.605558 \nL 365.356562 97.605558 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 15 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 101.725402)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-49\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 30.556563 54.462701 \nL 365.356562 54.462701 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 20 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 58.582545)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-50\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 30.556563 11.319844 \nL 365.356562 11.319844 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 25 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 15.439688)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-50\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 45.774744 227.034129 \nL 76.211108 227.034129 \nL 76.211108 123.491272 \nL 45.774744 123.491272 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 76.211108 227.034129 \nL 106.647472 227.034129 \nL 106.647472 19.948415 \nL 76.211108 19.948415 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 106.647472 227.034129 \nL 137.083835 227.034129 \nL 137.083835 37.205558 \nL 106.647472 37.205558 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 137.083835 227.034129 \nL 167.520199 227.034129 \nL 167.520199 140.748415 \nL 137.083835 140.748415 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 167.520199 227.034129 \nL 197.956563 227.034129 \nL 197.956563 175.262701 \nL 167.520199 175.262701 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 197.956563 227.034129 \nL 228.392926 227.034129 \nL 228.392926 175.262701 \nL 197.956563 175.262701 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 228.392926 227.034129 \nL 258.82929 227.034129 \nL 258.82929 183.891272 \nL 228.392926 183.891272 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 258.82929 227.034129 \nL 289.265653 227.034129 \nL 289.265653 227.034129 \nL 258.82929 227.034129 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 289.265653 227.034129 \nL 319.702017 227.034129 \nL 319.702017 227.034129 \nL 289.265653 227.034129 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path clip-path=\"url(#p7a4ff7eb67)\" d=\"M 319.702017 227.034129 \nL 350.138381 227.034129 \nL 350.138381 218.405558 \nL 319.702017 218.405558 \nz\n\" style=\"fill:#4c72b0;stroke:#ffffff;stroke-linejoin:miter;\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 30.556563 227.034129 \nL 30.556563 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 365.356562 227.034129 \nL 365.356562 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 30.556563 227.034129 \nL 365.356563 227.034129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 30.556563 9.594129 \nL 365.356563 9.594129 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p7a4ff7eb67\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.556563\" y=\"9.594129\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD/CAYAAADhYy38AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQkUlEQVR4nO3dbUjV9//H8dfx2LHlBTrRBqarXzd0rFyEVFQKu9GCwQhiWETFLnBCuSV5pK1GujbMLo4jVjDabi3WblUM1xas1jZaNLpaWThqlqtzYyY2KaWfHY/f3w3JP/63Op4rT73P83Fr59s55/vxzenZdx/1HJfjOI4AAE+8lEQvAAAQGwQdAIwg6ABgBEEHACMIOgAYQdABwAiCDgBGpI7lTu3t7WpqatLg4KCCwaC8Xq/mzJmjqqoq3b59Wx6PR5I0e/Zs1dfXx3XBAIB/FzLog4ODqq2t1a5du1RSUqLr169r1apV+vnnn9XV1aX9+/crIyNjPNYKAHiEkFsuLpdLO3bsUElJiSSpsLBQAwMD6u/v171794g5ADwmQl6hu91ulZaWSpICgYAaGxtVUVGh1NRUBYNBbdmyRVevXlVOTo68Xq+KiorCWsDff/draMjWuw/k5maop6cv0ct4LDCLYcxhGHMYFukcUlJcyslJf+ifu8b6Xi5+v191dXUqKytTbW2t+vv75fP5VFNTo8mTJ+v48ePy+Xz65ptvwl4kACB6Ywp6R0eHvF6vGhoaNGvWrIfeb+7cufr++++VlZU15gX09PSZu0LPy8tUd/fdRC/jscAshjGHYcxhWKRzSElxKTf34dvcIffQA4GA6uvr5fP5RsW8q6tLLS0tCgQCkqTTp08rOzs7rJgDAGIn5B76hQsXdPPmTW3atGnU8ffee09paWlaunSp0tPT5fF4tGfPnrgtFADwaGPeQ48XtlxsYxbDmMMw5jAsYVsuAIAnA0EHACMIOgAYMab3csH/ycx6ShPTQo8tLy8z5uf+78Cg7t65F/PnBWADQQ/TxLRUvVL3dULO3epbIr6dBOBh2HIBACMIOgAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjCDoAGAEQQcAIwg6ABhB0AHACIIOAEYQdAAwgqADgBEEHQCM4P3QnyD3A8G4fHBGKHywBvBkIOhPEM8Ed0I+XIMP1gCeDGy5AIARBB0AjCDoAGAEQQcAIwg6ABhB0AHACIIOAEYQdAAwgqADgBEEHQCMIOgAYARBBwAjxvTmXO3t7WpqatLg4KCCwaC8Xq/mzJmjc+fOadu2bQoEAsrOzlZzc7Py8/PjvWYAwL8IGfTBwUHV1tZq165dKikp0fXr17Vq1Sp99913WrdunT7//HMVFxfrq6++0ubNm/Xpp5+Ox7oBAP9PyC0Xl8ulHTt2qKSkRJJUWFiogYEBHT16VKWlpSouLpYkVVZWqq2tTb29vXFdMADg34UMutvtVmlpqSQpEAiooaFBFRUV6u7u1rRp00bdb8qUKfL7/fFbLQDgocb8ARd+v191dXUqKytTbW2t9u3bJ5fLNeo+LpfrH8dCyc3NCOv+SIxoPikpEZ+y9DhiDsOYw7B4zGFMQe/o6JDX61VDQ4NmzZolSSoqKtL58+dH7uM4jvx+vwoKCsJaQE9Pn4aGnLAek0jJ+mLs7o7sM4vy8jIjfqwlzGEYcxgW6RxSUlyPvAgOueUSCARUX18vn883EnNJKi8v18WLF3XlyhVJUmtrq2bMmKHs7OywFwkAiF7IK/QLFy7o5s2b2rRp06jjGzdulM/n04YNG+R2u5WVlaWtW7fGbaEAgEcLGfSysjKdPn36oX9+6NChmC4IABAZflMUAIwg6ABgBEEHACMIOgAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjCDoAGAEQQcAIwg6ABhB0AHACIIOAEYQdAAwgqADgBEEHQCMIOgAYARBBwAjCDoAGEHQAcAIgg4ARhB0ADCCoAOAEQQdAIwg6ABgBEEHACMIOgAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjAgZ9M7OTu3evVvz58/XmTNnxmNNAIAIpIa6w4EDB5Sbm6v8/PxRx6uqqnT79m15PB5J0uzZs1VfXx+fVQIAQgoZ9Lq6OknSsWPHRh3v6urS/v37lZGREZ+VAQDCEvEe+r1794g5ADxGQl6h/5t79+4pGAxqy5Ytunr1qnJycuT1elVUVBTr9QEAxiiioA8MDGjBggWqrq7W5MmTdfz4ca1Zs0bffPNN2M+Vm8tV/pMgLy8zIY+1hDkMYw7D4jGHiIKenZ2tDz/8cOT2iy++qHfffVd37txRVlZWWM/V09OnoSEnkmUkRLK+GLu770b0uLy8zIgfawlzGMYchkU6h5QU1yMvgiPaQ+/q6lJLS4sCgYAk6fTp08rOzg475gCA2InoCj0/P19paWlaunSp0tPT5fF4tGfPnlivDQAQhjEHfd++fSP/7XK5tHbtWq1duzYuiwIAhI9f/QcAIwg6ABhB0AHACIIOAEYQdAAwgqADgBEEHQCMIOgAYARBBwAjCDoAGEHQAcAIgg4ARhB0ADCCoAOAEQQdAIwg6ABgBEEHACMIOgAYQdABwAiCDgBGEHQAMCI10QuIVGbWU5qY9sQuHwBi7okt4sS0VL1S9/W4n7fVt2TczwkAY8GWCwAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjCDoAGAEQQcAIwg6ABhB0AHACIIOAEaEDHpnZ6d2796t+fPn68yZM+OxJgBABEIG/cCBA8rIyFB+fv6o4+fOndOyZcu0dOlSvfHGG7p161bcFgkACC1k0Ovq6vTaa68pMzNz5FhfX5/WrVunLVu26ODBg1q0aJE2b94c14UCAB4toj30EydOqLS0VMXFxZKkyspKtbW1qbe3N5ZrAwCEIaL3Q79x44amTZs2ctvtdmvKlCny+/3Kzs4O67lyczMiWQLG0f1AUHl5maHv+BDRPPZ+ICjPBHfEj3+cRDMHS5jDsHjMIaKgp6amyuVyjTrmcrn+cWwsenr6NDTkhP04XhTjxzPBnZAPE5GGP1Cku/tuQs4dS3l5mSa+jmgxh2GRziElxfXIi+CItlyKiorU2dk5cttxHPn9fhUUFETydACAGIgo6OXl5bp48aKuXLkiSWptbdWMGTPC3m4BAMRORFsuaWlp8vl82rBhg9xut7KysrR169ZYrw0AEIYxB33fvn2jbpeVlenQoUMxXxAAIDL86j8AGEHQAcAIgg4ARhB0ADCCoAOAEQQdAIwg6ABgBEEHACMIOgAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjCDoAGAEQQcAIwg6ABhB0AHACIIOAEYQdAAwgqADgBEEHQCMIOgAYARBBwAjCDoAGEHQAcAIgg4ARhB0ADCCoAOAEamJXgDwKPcDQeXlZY77eQfuB5Xmccf0Ocfydfx3YFB379yL6XmRPAg6HmueCW69Uvf1uJ+31bckYee9O+5nhRVsuQCAEQQdAIwg6ABgRNR76I2NjTp79qwyMjIkSYWFhdq+fXvUCwMAhCfqoP/111/auXOniouLY7EeAECEot5yuXXrlgoKCmKxFgBAFKK+Qu/t7dXevXv122+/KS0tTbW1tXr++efH/Pjc3IxolwCYkaifu39wbs+E2P7s/b9J1Nf3uInHHKIKuuM4mjdvnpYsWaL169erra1NNTU1Onz4sCZNmjSm5+jp6dPQkBP2uXlRwKJE/dy9NPwz8N3d8f0p+Ly8zLif40kQ6RxSUlyPvAiOasvF5XKpqalJ06dPlyTNnDlTOTk5+vPPP6N5WgBABKIKen9/v5qbm9XX1ydJ6ujoUE9Pj4qKimKyOADA2EW15ZKenq6pU6dqxYoVI1ssLS0tSk9Pj8niAABjF/U3RZcvX67ly5fHYi0AgCjwm6IAYARBBwAjCDoAGEHQAcAIgg4ARhB0ADCCoAOAEQQdAIwg6ABgBEEHACMIOgAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjCDoAGAEQQcAIwg6ABhB0AHACIIOAEYQdAAwgqADgBEEHQCMIOgAYARBBwAjCDoAGEHQAcAIgg4ARqQmegEAkCiZWU9pYtr4Z/B+IBiX5yXoAJLWxLRUvVL39bift9W3JC7Py5YLABhB0AHACIIOAEZEHfSOjg6tWrVKS5cu1fLly9XR0RGLdQEAwhRV0IeGhvT222/rrbfe0sGDB7VmzRrV1tbGaGkAgHBE9VMuly9flsfjUXl5uSSpoqJCLS0tam9v13PPPTem50hJcUV8/vycpyJ+bDQSdd5Enpuv2f55pej+Pj5O5whHouYdyRxCPcblOI4T6YIOHz6so0eP6uOPPx45tn79ei1evFiLFy+O9GkBABGIasslNTVVLtfofzFcLtc/jgEA4i+qoD/77LPq7Owcdayzs1NFRUXRPC0AIAJRBb2kpESBQEAnT56UJJ05c0aBQEAlJSUxWRwAYOyi2kOXpD/++EPvv/++BgcHNWHCBH300UeaPn16rNYHABijqIMOAHg88JuiAGAEQQcAIwg6ABhB0AHACIIepc7OTu3evVvz58/XmTNnEr0cAEmMTyyK0oEDB5Sbm6v8/PxRx8+dO6dt27YpEAgoOztbzc3N/7iPJe3t7WpqatLg4KCCwaC8Xq/mzJmTdHP48ssvdfDgQaWkpGjSpElqaGjQf/7zn6SbwwOXLl3SihUr9Nlnn2nu3LlJOYfGxkadPXtWGRkZkqTCwkJt3749PrNwEBMrV650Tp8+7TiO49y9e9dZuHCh8/vvvzuO4zj79+93qqurE7m8uAoEAs5LL73ktLe3O47jONeuXXMWLFjg3LlzJ6nm0NPT4zQ0NDgDAwOO4zjODz/84KxevTrpXg8P/P33386yZcuc6upq59SpU0k7h+rq6pGv+YF4zYItlzg4ceKESktLVVxcLEmqrKxUW1ubent7E7uwOHG5XNqxY8fIbwgXFhZqYGBAR48eTao5PP3002psbJTH45HjOOrs7JTL5Uq614M0/Nba9fX1qqmpUXZ2tqTk+3vxwK1bt1RQUDDqWLxmQdDj4MaNG5o2bdrIbbfbrSlTpsjv9ydwVfHjdrtVWloqSQoEAmpoaFBFRYW6u7uTag4P7Ny5UwsXLtTJkyf1wQcfJN3rQZI++eQTlZaWauHChSPHknEOktTb26u9e/dq9erVqqqq0uXLl+M2C4IeB8n6LpR+v18rV64c2Q9M1jl4vV4dP35cL7zwgn755Zekm8OPP/6oS5cuae3ataOOJ9scJMlxHM2bN09LlizRF198oXfeeUc1NTUKBoNxmQXfFI2DoqIinT9/fuS24zjy+/3/+N8uSzo6OuT1etXQ0KBZs2ZJSs45OI4jl8slj8ejN998U+Xl5Wpubk6qOXz77be6du2aXn75ZUlSd3e3Tp06pVdffXXUu7Nan4M0HOmmpqaR2zNnzlROTo6CwWBcZsEVehyUl5fr4sWLunLliiSptbVVM2bMGNlLtCYQCKi+vl4+n28k5lLyzeGnn37S+vXrNTg4KEn69ddf9cwzzyTdHLZv365jx47pyJEjOnLkiBYtWqRt27apqqoqqeYgSf39/WpublZfX5+k4Qufnp4evf7663GZBVfocZCWliafz6cNGzbI7XYrKytLW7duTfSy4ubChQu6efOmNm3aNOr4xo0bk2oO5eXlunTpkiorK+XxeJSSkqLt27cn3evhYZJxDunp6Zo6dapWrFihSZMmSZJaWlqUnp4el1nwbosAYARbLgBgBEEHACMIOgAYQdABwAiCDgBGEHQAMIKgA4ARBB0AjPgfByRFR50GNVIAAAAASUVORK5CYII=\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.hist(data[\"文字数\"])"
   ]
  },
  {
   "source": [
    "以上に長いコメントがありますね。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           日付                                               コメント  満足度  文字数\n",
       "41  2019/2/25                                               特になし    3    4\n",
       "69   2019/1/4                                               特になし    2    4\n",
       "25  2019/1/21                                               道が綺麗    4    4\n",
       "18  2019/3/15                                              夜道が暗い    1    5\n",
       "19  2019/2/20                                             ゴミ処理が楽    4    6\n",
       "..        ...                                                ...  ...  ...\n",
       "62  2019/3/19                  アンケートをちゃんと確認して街づくりに反映してくれている姿勢が良い    5   33\n",
       "56  2019/4/13                  歩行者用信号が変わるのが早い。老人や子供の事を考えて設定してほしい    2   33\n",
       "44  2019/2/28                信号のない交差点が近くにあり事故が起きそうで怖い、信号を付けて欲しい。    1   35\n",
       "39  2019/3/11                変なおじさんに声を掛けられた事がある。警察の巡回をもっと強化してほしい    1   35\n",
       "43  2019/3/11  最近川の氾濫被害が大きく取り扱われているが、この町ではどのような氾濫防止を取っているか説明し...    3   50\n",
       "\n",
       "[86 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>日付</th>\n      <th>コメント</th>\n      <th>満足度</th>\n      <th>文字数</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>41</th>\n      <td>2019/2/25</td>\n      <td>特になし</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>2019/1/4</td>\n      <td>特になし</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>2019/1/21</td>\n      <td>道が綺麗</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2019/3/15</td>\n      <td>夜道が暗い</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2019/2/20</td>\n      <td>ゴミ処理が楽</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>2019/3/19</td>\n      <td>アンケートをちゃんと確認して街づくりに反映してくれている姿勢が良い</td>\n      <td>5</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>2019/4/13</td>\n      <td>歩行者用信号が変わるのが早い。老人や子供の事を考えて設定してほしい</td>\n      <td>2</td>\n      <td>33</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>2019/2/28</td>\n      <td>信号のない交差点が近くにあり事故が起きそうで怖い、信号を付けて欲しい。</td>\n      <td>1</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>2019/3/11</td>\n      <td>変なおじさんに声を掛けられた事がある。警察の巡回をもっと強化してほしい</td>\n      <td>1</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>2019/3/11</td>\n      <td>最近川の氾濫被害が大きく取り扱われているが、この町ではどのような氾濫防止を取っているか説明し...</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n<p>86 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "data.sort_values(by=\"文字数\")"
   ]
  },
  {
   "source": [
    "### 単語レベルの解析\n",
    "\n",
    "コメントから単語を抽出して、どのような単語が使われているか調べてみましょう。\n",
    "\n",
    "* 標準形変換: 活用のある単語（例. 「買った」）は、買うのように標準形に変換する\n",
    "* [ストップワード除外](https://mieruca-ai.com/ai/nlp-stopwords/#toc_2-1): 解析の精度を上げるために不要な記号や単語を取り除く\n",
    "\n",
    "ここでは、動詞、形容詞、名詞だけに着目してみます。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "375\n['駅前', '若者', '集まる', 'スポーツ', '場所', 'ある', '良い', '子育て', '支援', '嬉しい', '保育園', '入れる', '待機児童', 'なし', '駅前', '商店街', '寂しい', '生活', '便利', '遊ぶ', '場所', 'ない', '遊ぶ', '場所', 'ない', '商業', '施設', '出来る', '欲しい', '病院']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for text in data[\"コメント\"]:\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        # 動詞(VERB), 名詞(NOUN), 形容詞(ADJ)のみ抽出\n",
    "        if word.pos_ == 'VERB' or word.pos_ == 'NOUN' or word.pos_ == 'ADJ':\n",
    "            words.append(word.lemma_)\n",
    "print(len(words))\n",
    "print(words[:30])"
   ]
  },
  {
   "source": [
    "これで、コメント文の中で用いられている名詞と動詞をすべて取り出すことができました。しかし、\n",
    "まだどれの単語が重要なのかわかりません。各単語の出現頻度を調べてみましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "words\n",
       "欲しい      15\n",
       "ほしい      14\n",
       "少ない       7\n",
       "駅前        7\n",
       "良い        6\n",
       "         ..\n",
       "大丈夫       1\n",
       "奇麗        1\n",
       "姿勢        1\n",
       "子ども       1\n",
       "高齢者       1\n",
       "Length: 228, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "pd.DataFrame({\"words\":words}).value_counts()\n"
   ]
  },
  {
   "source": [
    "これで不動産の満足度に影響を与えているキーワードが見えてきました。しかし、まだどのキーワードがプラスの評価なのか、マイナスの評価なのかわかりません。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Let's try\n",
    "\n",
    "満足度の高いキーワードを抽出してみよう\n",
    "\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 満足度の高いキーワード\n",
    "\n",
    "今回のアッケート調査の素晴らしいことは、不動産の満足度が 5 段階評価で回答されています。\n",
    "各キーワードとこの5段階評価を紐付けてみると、キーワードの満足度が見えて来るかもしれません。 \n",
    "(見えてくるかもというだけで、保証はありません。)\n",
    "\n",
    "まず、名詞と動詞を抽出したとき、アンケート結果の満足度も対応付けるように取り出します。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['駅前', '若者', '集まる', 'スポーツ', '場所', 'ある', '良い', '子育て', '支援', '嬉しい', '保育園', '入れる', '待機児童', 'なし', '駅前', '商店街', '寂しい', '生活', '便利', '遊ぶ', '場所', 'ない', '遊ぶ', '場所', 'ない', '商業', '施設', '出来る', '欲しい', '病院', '充実', 'サイクリングコース', '良い', 'お祭り', '盛り上げる', '欲しい', '小学校', '綺麗', '嬉しい', '公園', '欲しい', '近く', '公園', 'ある', '住む', 'スーパー', '行く', '大変', '子育て', 'デート', 'スポット', '欲しい', '商店街', '盛り上げる', 'ほしい', '夜道', '暗い', 'ゴミ', '処理', '楽', '映画館', '欲しい', '街路樹', '欲しい', '公園', '追加', '欲しい', '観光', 'スポット', 'ない', '子育て', 'する', '道', '綺麗', '都内', 'アクセス', '良い', '家賃', 'リーズナブル', 'bbb', '渋滞', 'する', '欲しい', '商店街', '屋根', 'ない', '雨', '降る', '大変', '商店街', '喫茶店', '欲しい', 'スポーツジム', 'ある', '利用', 'スポーツジム', '利用料金', '高い', '働く', 'ママ', '支援', '増やす', '欲しい', 'バス', 'くる', '自転車', '走る', 'ランニング', '運動', '場所', '多い', '有名', '企業', '多い', '駅前', '駐車場', '足りる', '変', 'おじ', 'さん', '声', '掛ける', '事', 'ある', '警察', '巡回', '強化', 'ほしい', '消防団', '活発', '安心', 'なし', '災害', '時', '避難', '場所', '少ない', '気', 'する', '最近', '川', '氾濫', '被害', '大きい', '取り扱う', '町', '氾濫', '防止', '取る', '説明', 'ほしい', '信号', 'ない', '交差点', '近く', 'ある', '事故', '起きる', '怖い', '信号', '付ける', '欲しい', '商店街', '活性化', '活動', '行政', '後押し', 'ほしい', '子ども', '安全', '遊ぶ', '場所', 'ない', '駅前', '駐輪場', '無い', '不便', '街路樹', '落ち葉', '掃除', '街路樹', 'やめる', 'ほしい', '災害', '時', '備蓄', '状況', 'なる', '歩道', '広い', '道', '多い', '安心', '地域', '自治体', '支援', 'ほしい', '自治体', '活動', '頻繁', '安心', '暮らせる', '観光地', '少ない', '最近', '他県', 'ナンバー', '車', '多い', '防犯', '出来る', '駐車場', '数', '少ない', '料金', '高い', '駅前', '公共', '駐車場', '作る', '欲しい', '歩行者', '用', '信号', '変わる', '早い', '老人', '子供', '事', '考える', '設定', 'ほしい', '急行', '止まる', '都内', '出る', '良い', 'バス', '路線', '増やす', 'ほしい', '春', '桜', '並木', '最高', '綺麗', '増やす', 'ほしい', '隣町', 'できる', 'ごみ', '処理', '施設', '心配', '公害', '大丈夫', '市長', '若い', '活気', 'ある', 'アンケート', '確認', '街づくり', '反映', '姿勢', '良い', '先月', '職員', '不正', '事件', 'つく', '詳細', '説明', 'ほしい', '役所', '担当者', '無愛想', '気', '入る', '役所', '出張所', '駅前', '作る', '欲しい', '役所', '土日', '開く', '助かる', '災害', '時', '避難', '経路', '分かる', '表示', 'ほしい', '市', 'ホームページ', '奇麗', '分かる', 'なし', '役所', '電話', '繋がる', '対応', '者', '増やす', '細い', '路地', '街頭', '少ない', '怖い', '動物園', '欲しい', '冬場', '路面', '凍結', '事故', '多い', '対応', '自然', '豊か', '過ごす', '野良猫', 'よる', '糞害', 'ひどい', '行政', '野良猫', '対策', 'する', '役所', '相談', '行く', 'とき', '親身', '対応', '高速道路', '出る', '道', '狭い', '渋滞', 'ひどい', '拡幅', 'ほしい', 'まち', 'マスコット', '作る', '夜間', '対応', '病院', '少ない', '不安', '高齢者', 'サポート', '施設', '欲しい', '小学校', '校庭', '芝生', '良い', 'ホームページ', 'アンケート', '投稿', 'ほしい', '公園', '遊び道具', '少ない', 'すぎる', '公園', '増やす', 'ほしい', '駅前', '駐車場', '少ない', '不便']\n[1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 3, 3, 3, 3, 4, 4, 5, 5, 2, 2, 2, 4, 4, 4, 2, 2, 4, 4, 4, 4, 1, 1, 1, 4, 3, 3, 3, 4, 4, 4, 1, 1, 4, 4, 4, 2, 2, 3, 3, 2, 2, 2, 1, 1, 1, 4, 4, 4, 4, 5, 5, 5, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 4, 4, 5, 5, 5, 5, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 4, 4, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 5, 5, 5, 5, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 4, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 5, 5, 5, 5, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "scores = []\n",
    "for text, score in zip(data[\"コメント\"], data[\"満足度\"]):\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        if word.pos_ in ['VERB', 'NOUN', 'ADJ']:\n",
    "            words.append(word.lemma_)\n",
    "            scores.append(score)\n",
    "print(words)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            満足度  出現数\n",
       "キーワード               \n",
       "bbb    2.000000    1\n",
       "暗い     1.000000    1\n",
       "暮らせる   5.000000    1\n",
       "最高     5.000000    1\n",
       "有名     3.000000    1\n",
       "...         ...  ...\n",
       "良い     4.833333    6\n",
       "少ない    1.142857    7\n",
       "駅前     1.428571    7\n",
       "ほしい    2.000000   14\n",
       "欲しい    2.200000   15\n",
       "\n",
       "[228 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>満足度</th>\n      <th>出現数</th>\n    </tr>\n    <tr>\n      <th>キーワード</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>bbb</th>\n      <td>2.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>暗い</th>\n      <td>1.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>暮らせる</th>\n      <td>5.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>最高</th>\n      <td>5.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>有名</th>\n      <td>3.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>良い</th>\n      <td>4.833333</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>少ない</th>\n      <td>1.142857</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>駅前</th>\n      <td>1.428571</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>ほしい</th>\n      <td>2.000000</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>欲しい</th>\n      <td>2.200000</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n<p>228 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "keyword = pd.DataFrame({\"キーワード\": words, \"満足度\": scores, \"出現数\": [1]*len(words)})\n",
    "keyword.groupby('キーワード').agg({'満足度': np.mean, '出現数': sum}).sort_values(by='出現数')"
   ]
  },
  {
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Let's try\n",
    "\n",
    "満足度の高いキーワードと満足度の低いキーワードのトップ 5 を出してみよう\n",
    "\n",
    "</div>\n",
    "\n",
    "今回の分析は、出現頻度のあまりに低い単語を除外した方が良いです。このように、データサイエ ンティスト(分析者)のセンスで、結果は少し変わります。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 文章のベクトル化\n",
    "\n",
    "次は、いよいよ文章のベクトル化を考えていきます。\n",
    "ポイントは、意味や内容が近い文章は近くなるようにベクトル化することです。\n",
    "類似文章検索として研究されてきました。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### BOW\n",
    "\n",
    "**BOW(Bag of Words)** は最も古典的な文書の特徴量を捉えてベクトル化する手法です。\n",
    "出現する単語の個数を $N$ とすると、各コメント文は出現した単語には 1 を入れた $N$ 次元のベクトルで表現します。\n",
    "\n",
    "\n",
    "単語の並びを無視しているので Bag of Words（以後、BOW）と呼ばれます。語順を無視すると重要な情報が飛んでしまいそうな気がしますが、類似文書検索タスクでは、十分精度がでます。\n",
    "\n",
    "\n",
    "\n",
    "BOW のポイントは、文章の構造は全て無視し、「どの単語が含まれているか」だけに注目している点です。そして、一旦、コメント文をベクトルで表現できれば、**コサイン類似度 (cosine similarity) **を用いて、類似度を求めることができます。\n",
    "\n",
    "BOW の原理は、難しくありません。sklearnモジュールの`CountVectorizer`を使って、楽に BOW を求めることができます。ただし、sklearn は、英語圏で開発されたライブラリなので、入力文は英単語のように空白で区 切られているという前提になっています。日本語は、形態素解析を使って前処理して、テキストを空白区切りの形式に変換しておく必要があります。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          日付              コメント  満足度  文字数                    わかち書き\n",
       "0  2019/3/11      駅前に若者が集まっている    1   12       駅前 に 若者 が 集まる て いる\n",
       "1  2019/2/25  スポーツできる場所があるのが良い    5   16  スポーツ できる 場所 が ある の が 良い\n",
       "2  2019/2/18         子育て支援が嬉しい    5    9             子育て 支援 が 嬉しい\n",
       "3   2019/4/9   保育園に入れる（待機児童なし）    4   15    保育園 に 入れる （ 待機児童 なし )\n",
       "4   2019/1/6         駅前商店街が寂しい    2    9             駅前 商店街 が 寂しい"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>日付</th>\n      <th>コメント</th>\n      <th>満足度</th>\n      <th>文字数</th>\n      <th>わかち書き</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2019/3/11</td>\n      <td>駅前に若者が集まっている</td>\n      <td>1</td>\n      <td>12</td>\n      <td>駅前 に 若者 が 集まる て いる</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2019/2/25</td>\n      <td>スポーツできる場所があるのが良い</td>\n      <td>5</td>\n      <td>16</td>\n      <td>スポーツ できる 場所 が ある の が 良い</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2019/2/18</td>\n      <td>子育て支援が嬉しい</td>\n      <td>5</td>\n      <td>9</td>\n      <td>子育て 支援 が 嬉しい</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2019/4/9</td>\n      <td>保育園に入れる（待機児童なし）</td>\n      <td>4</td>\n      <td>15</td>\n      <td>保育園 に 入れる （ 待機児童 なし )</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2019/1/6</td>\n      <td>駅前商店街が寂しい</td>\n      <td>2</td>\n      <td>9</td>\n      <td>駅前 商店街 が 寂しい</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "data['わかち書き'] = data['コメント'].map(lambda x: ' '.join(wakachi(x)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0 0 0 ... 0 0 0]\n [0 0 1 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "docs = np.array(data['わかち書き'])\n",
    "model = CountVectorizer()\n",
    "bags = model.fit_transform(docs)\n",
    "\n",
    "print(bags.toarray())"
   ]
  },
  {
   "source": [
    "Pandasで表デートしてみてみましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  bbb  あまり  ある  いる  おじ  お祭り  から  くる  くれる  けど  ...  隣町  集まる  \\\n",
       "コメント                                                          ...            \n",
       "駅前に若者が集まっている        0    0   0   1   0    0   0   0    0   0  ...   0    1   \n",
       "スポーツできる場所があるのが良い    0    0   1   0   0    0   0   0    0   0  ...   0    0   \n",
       "子育て支援が嬉しい           0    0   0   0   0    0   0   0    0   0  ...   0    0   \n",
       "保育園に入れる（待機児童なし）     0    0   0   0   0    0   0   0    0   0  ...   0    0   \n",
       "駅前商店街が寂しい           0    0   0   0   0    0   0   0    0   0  ...   0    0   \n",
       "\n",
       "                  電話  頻繁  駅前  駐車場  駐輪場  高い  高速道路  高齢者  \n",
       "コメント                                                   \n",
       "駅前に若者が集まっている       0   0   1    0    0   0     0    0  \n",
       "スポーツできる場所があるのが良い   0   0   0    0    0   0     0    0  \n",
       "子育て支援が嬉しい          0   0   0    0    0   0     0    0  \n",
       "保育園に入れる（待機児童なし）    0   0   0    0    0   0     0    0  \n",
       "駅前商店街が寂しい          0   0   1    0    0   0     0    0  \n",
       "\n",
       "[5 rows x 237 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bbb</th>\n      <th>あまり</th>\n      <th>ある</th>\n      <th>いる</th>\n      <th>おじ</th>\n      <th>お祭り</th>\n      <th>から</th>\n      <th>くる</th>\n      <th>くれる</th>\n      <th>けど</th>\n      <th>...</th>\n      <th>隣町</th>\n      <th>集まる</th>\n      <th>電話</th>\n      <th>頻繁</th>\n      <th>駅前</th>\n      <th>駐車場</th>\n      <th>駐輪場</th>\n      <th>高い</th>\n      <th>高速道路</th>\n      <th>高齢者</th>\n    </tr>\n    <tr>\n      <th>コメント</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>駅前に若者が集まっている</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>スポーツできる場所があるのが良い</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>子育て支援が嬉しい</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>保育園に入れる（待機児童なし）</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>駅前商店街が寂しい</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 237 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "pd.DataFrame(bags.toarray(),columns=model.get_feature_names(),index=data['コメント']).head()"
   ]
  },
  {
   "source": [
    "文章をベクトル化できれば、あとは類似度を計算するだけです。計算の仕方もいろいろですが、コサイン類似度を用いることが多いです 。ベクトルの向きがどの程度同じ方向を向いているか？という指標で、－１～１の範囲をとります。コサイン類似度を数式で記述すると以下のようになります。\n",
    "$$\n",
    "cos(θ)= \n",
    "∥ \n",
    "x\n",
    " ∥∥ \n",
    "y\n",
    "​\t\n",
    " ∥\n",
    "x\n",
    " ⋅ \n",
    "y\n",
    "​\t\n",
    " \n",
    "​\t\n",
    " = \n",
    "∑ \n",
    "i\n",
    "​\t\n",
    " x \n",
    "i\n",
    "2\n",
    "​\t\n",
    " \n",
    "​\t\n",
    " × \n",
    "∑ \n",
    "i\n",
    "​\t\n",
    " y \n",
    "i\n",
    "2\n",
    "​\t\n",
    " \n",
    "​\t\n",
    " \n",
    "∑ \n",
    "i\n",
    "​\t\n",
    " x \n",
    "i\n",
    "​\t\n",
    " y \n",
    "i\n",
    "​\t\n",
    " \n",
    "​\t\n",
    " \n",
    "$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosin_similarity(x, y):\n",
    "    return np.dot(x, y)/(np.sqrt(np.dot(x, x))*np.sqrt(np.dot(y, y)))"
   ]
  },
  {
   "source": [
    "### TF/IDF\n",
    "\n",
    "BOW は、単語の出現を見るだけで、重要度はわかりません。前回、勉強した TF/IDF を組み合わ せることで、出現に重み付けすることができます。こちらも、scikit-learn のライブラリを用いることができます。\n",
    "\n",
    "TF-IDF は Term Frequency – Inverse Document Frequency の略で、文書中の単語の重要度を評価する手法の一つです。Solr や Elastic Search で有名な Lucene でも少し前までデフォルトのアルゴリズムだったのでご存じの方も多いかと思います。TF, IDF はそれぞれ以下のような意味合いで、TF と IDF の積が TF-IDF です*1。\n",
    "\n",
    "TF(t,d) … ある単語(t)がある文書(d)中で何回出現したか\n",
    "IDF(t) … ある単語(t)が全文書集合(D)中のどれだけの文書で出現したかの逆数\n",
    "早い話が「ある文書の中で何度も出現する単語は重要度が高いが、多くの文書に共通して出現する単語はそうでもない」と理解してもらえれば良いです。文書 d 中の単語 t の TF-IDF(t, d) は以下のようになります。\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "feature_names: ['bbb', 'あまり', 'ある', 'いる', 'おじ', 'お祭り', 'から', 'くる', 'くれる', 'けど', 'この', 'ごみ', 'さん', 'すぎる', 'する', 'そう', 'たくさん', 'ちゃんと', 'つく', 'できる', 'とき', 'とても', 'どう', 'どのような', 'ない', 'なし', 'なる', 'なん', 'ひどい', 'ほしい', 'ます', 'まち', 'まで', 'もう', 'もっと', 'やすい', 'やめる', 'よう', 'よく', 'よる', 'られる', 'れる', 'アクセス', 'アンケート', 'ゴミ', 'サイクリングコース', 'サポート', 'スポット', 'スポーツ', 'スポーツジム', 'スーパー', 'デート', 'ナンバー', 'バス', 'ホームページ', 'マスコット', 'ママ', 'ランニング', 'リーズナブル', '下さる', '不便', '不安', '不正', '並木', '事件', '事故', '交差点', '他県', '付ける', '企業', '住む', '作る', '便利', '保育園', '信号', '備蓄', '働く', '充実', '先月', '入る', '入れる', '公共', '公園', '公害', '冬場', '凍結', '処理', '出る', '出張所', '出来る', '分かる', '利用', '利用料金', '助かる', '動物園', '反映', '取り扱う', '取る', '商店街', '商業', '喫茶店', '土日', '地域', '場所', '増やす', '変わる', '多い', '夜道', '夜間', '大きい', '大丈夫', '大変', '奇麗', '姿勢', '嬉しい', '子ども', '子供', '子育て', '安全', '安心', '家賃', '寂しい', '対応', '対策', '小学校', '少し', '少ない', '屋根', '巡回', '市長', '広い', '強化', '役所', '待機児童', '後押し', '心配', '怖い', '急行', '投稿', '担当者', '拡幅', '掃除', '掛ける', '支援', '料金', '施設', '早い', '映画館', '暗い', '暮らせる', '最近', '最高', '有名', '校庭', '桜並木', '欲しい', '止まる', '歩行者', '歩道', '氾濫', '活動', '活性化', '活気', '活発', '消防団', '渋滞', '災害', '無い', '無愛想', '特に', '状況', '狭い', '生活', '病院', '盛り上げる', '相談', '確認', '糞害', '細い', '経路', '綺麗', '繋がる', '老人', '考える', '職員', '自治体', '自然', '自転車', '良い', '芝生', '若い', '若者', '落ち葉', '行く', '行政', '街づくり', '街路樹', '街頭', '表示', '被害', '親身', '観光', '観光地', '設定', '詳細', '説明', '警察', '豊か', '走る', '起きる', '足りる', '路地', '路線', '路面', '近く', '追加', '遊び道具', '遊ぶ', '運動', '過ごす', '避難', '都内', '野良猫', '開く', '防止', '防犯', '降る', '隣町', '集まる', '電話', '頻繁', '駅前', '駐車場', '駐輪場', '高い', '高速道路', '高齢者']\nX:\n[[0.   0.   0.   ... 0.   0.   0.  ]\n [0.   0.   0.42 ... 0.   0.   0.  ]\n [0.   0.   0.   ... 0.   0.   0.  ]\n ...\n [0.   0.   0.   ... 0.   0.   0.  ]\n [0.   0.   0.   ... 0.   0.   0.  ]\n [0.   0.   0.   ... 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# tf-idf\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.9) #文書全体の90%以上で出現する単語は無視する\n",
    "X = vectorizer.fit_transform(data['わかち書き'])\n",
    "print('feature_names:', vectorizer.get_feature_names())\n",
    "print('X:')\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X[1, vectorizer.vocabulary_['隣町']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  bbb  あまり        ある        いる   おじ  お祭り   から   くる  くれる   けど  \\\n",
       "コメント                                                                           \n",
       "駅前に若者が集まっている      0.0  0.0  0.000000  0.397231  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "スポーツできる場所があるのが良い  0.0  0.0  0.416521  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "子育て支援が嬉しい         0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "保育園に入れる（待機児童なし）   0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "駅前商店街が寂しい         0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "                  ...   隣町       集まる   電話   頻繁        駅前  駐車場  駐輪場   高い  高速道路  \\\n",
       "コメント              ...                                                           \n",
       "駅前に若者が集まっている      ...  0.0  0.580016  0.0  0.0  0.411545  0.0  0.0  0.0   0.0   \n",
       "スポーツできる場所があるのが良い  ...  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0   0.0   \n",
       "子育て支援が嬉しい         ...  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0   0.0   \n",
       "保育園に入れる（待機児童なし）   ...  0.0  0.000000  0.0  0.0  0.000000  0.0  0.0  0.0   0.0   \n",
       "駅前商店街が寂しい         ...  0.0  0.000000  0.0  0.0  0.490089  0.0  0.0  0.0   0.0   \n",
       "\n",
       "                  高齢者  \n",
       "コメント                   \n",
       "駅前に若者が集まっている      0.0  \n",
       "スポーツできる場所があるのが良い  0.0  \n",
       "子育て支援が嬉しい         0.0  \n",
       "保育園に入れる（待機児童なし）   0.0  \n",
       "駅前商店街が寂しい         0.0  \n",
       "\n",
       "[5 rows x 237 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bbb</th>\n      <th>あまり</th>\n      <th>ある</th>\n      <th>いる</th>\n      <th>おじ</th>\n      <th>お祭り</th>\n      <th>から</th>\n      <th>くる</th>\n      <th>くれる</th>\n      <th>けど</th>\n      <th>...</th>\n      <th>隣町</th>\n      <th>集まる</th>\n      <th>電話</th>\n      <th>頻繁</th>\n      <th>駅前</th>\n      <th>駐車場</th>\n      <th>駐輪場</th>\n      <th>高い</th>\n      <th>高速道路</th>\n      <th>高齢者</th>\n    </tr>\n    <tr>\n      <th>コメント</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>駅前に若者が集まっている</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.397231</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.580016</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.411545</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>スポーツできる場所があるのが良い</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.416521</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>子育て支援が嬉しい</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>保育園に入れる（待機児童なし）</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>駅前商店街が寂しい</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.490089</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 237 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names(),index=data['コメント']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=8)\n",
    "pca.fit(model_tfidf.toarray())\n",
    "print(pca.n_components_)\n",
    "pc8 = pca.transform(model_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "np.set_printoptions(suppress=True)\n",
    "# SVD\n",
    "svd = TruncatedSVD(n_components=8, n_iter=7, random_state=0)\n",
    "svd.fit(X.toarray())\n",
    "X = svd.transform(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                        0         1         2         3  \\\n",
       "コメント                                                                      \n",
       "駅前に若者が集まっている                 7.731770e-02  0.055635  0.221337  0.258149   \n",
       "スポーツできる場所があるのが良い             9.653416e-02  0.232015  0.242801 -0.275236   \n",
       "子育て支援が嬉しい                    1.530323e-01  0.241557 -0.164930  0.098121   \n",
       "保育園に入れる（待機児童なし）              1.993400e-07 -0.000112  0.000043  0.000067   \n",
       "駅前商店街が寂しい                    1.475882e-01 -0.066456  0.235868  0.196006   \n",
       "...                                   ...       ...       ...       ...   \n",
       "小学校の校庭が芝生なのでとても良い            3.357989e-02  0.109346  0.002445 -0.019058   \n",
       "ホームページからアンケートを投稿できるようにしてほしい  2.061109e-01  0.200964 -0.030146 -0.113776   \n",
       "公園に遊び道具が少なすぎる                1.735468e-01 -0.023439  0.093533  0.130378   \n",
       "もっと公園を増やしてほしい                5.883562e-01 -0.202565 -0.184834 -0.231458   \n",
       "駅前に駐車場が少ない、不便                1.226444e-01  0.017410  0.509561  0.516643   \n",
       "\n",
       "                                    4         5         6         7  \n",
       "コメント                                                                 \n",
       "駅前に若者が集まっている                -0.183296 -0.000305  0.136036 -0.064076  \n",
       "スポーツできる場所があるのが良い             0.224877 -0.002571  0.282702  0.372138  \n",
       "子育て支援が嬉しい                    0.093775 -0.002967 -0.276363  0.062022  \n",
       "保育園に入れる（待機児童なし）             -0.000063  0.508183 -0.004800  0.000048  \n",
       "駅前商店街が寂しい                   -0.265106  0.001276 -0.074943  0.076161  \n",
       "...                               ...       ...       ...       ...  \n",
       "小学校の校庭が芝生なのでとても良い            0.079640  0.002153  0.071718  0.297933  \n",
       "ホームページからアンケートを投稿できるようにしてほしい -0.090526 -0.001596  0.202042  0.033840  \n",
       "公園に遊び道具が少なすぎる               -0.037278  0.001100  0.007060  0.216022  \n",
       "もっと公園を増やしてほしい               -0.253843 -0.003732 -0.064550  0.201424  \n",
       "駅前に駐車場が少ない、不便               -0.314527 -0.003270 -0.066299  0.261483  \n",
       "\n",
       "[86 rows x 8 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n    </tr>\n    <tr>\n      <th>コメント</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>駅前に若者が集まっている</th>\n      <td>7.731770e-02</td>\n      <td>0.055635</td>\n      <td>0.221337</td>\n      <td>0.258149</td>\n      <td>-0.183296</td>\n      <td>-0.000305</td>\n      <td>0.136036</td>\n      <td>-0.064076</td>\n    </tr>\n    <tr>\n      <th>スポーツできる場所があるのが良い</th>\n      <td>9.653416e-02</td>\n      <td>0.232015</td>\n      <td>0.242801</td>\n      <td>-0.275236</td>\n      <td>0.224877</td>\n      <td>-0.002571</td>\n      <td>0.282702</td>\n      <td>0.372138</td>\n    </tr>\n    <tr>\n      <th>子育て支援が嬉しい</th>\n      <td>1.530323e-01</td>\n      <td>0.241557</td>\n      <td>-0.164930</td>\n      <td>0.098121</td>\n      <td>0.093775</td>\n      <td>-0.002967</td>\n      <td>-0.276363</td>\n      <td>0.062022</td>\n    </tr>\n    <tr>\n      <th>保育園に入れる（待機児童なし）</th>\n      <td>1.993400e-07</td>\n      <td>-0.000112</td>\n      <td>0.000043</td>\n      <td>0.000067</td>\n      <td>-0.000063</td>\n      <td>0.508183</td>\n      <td>-0.004800</td>\n      <td>0.000048</td>\n    </tr>\n    <tr>\n      <th>駅前商店街が寂しい</th>\n      <td>1.475882e-01</td>\n      <td>-0.066456</td>\n      <td>0.235868</td>\n      <td>0.196006</td>\n      <td>-0.265106</td>\n      <td>0.001276</td>\n      <td>-0.074943</td>\n      <td>0.076161</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>小学校の校庭が芝生なのでとても良い</th>\n      <td>3.357989e-02</td>\n      <td>0.109346</td>\n      <td>0.002445</td>\n      <td>-0.019058</td>\n      <td>0.079640</td>\n      <td>0.002153</td>\n      <td>0.071718</td>\n      <td>0.297933</td>\n    </tr>\n    <tr>\n      <th>ホームページからアンケートを投稿できるようにしてほしい</th>\n      <td>2.061109e-01</td>\n      <td>0.200964</td>\n      <td>-0.030146</td>\n      <td>-0.113776</td>\n      <td>-0.090526</td>\n      <td>-0.001596</td>\n      <td>0.202042</td>\n      <td>0.033840</td>\n    </tr>\n    <tr>\n      <th>公園に遊び道具が少なすぎる</th>\n      <td>1.735468e-01</td>\n      <td>-0.023439</td>\n      <td>0.093533</td>\n      <td>0.130378</td>\n      <td>-0.037278</td>\n      <td>0.001100</td>\n      <td>0.007060</td>\n      <td>0.216022</td>\n    </tr>\n    <tr>\n      <th>もっと公園を増やしてほしい</th>\n      <td>5.883562e-01</td>\n      <td>-0.202565</td>\n      <td>-0.184834</td>\n      <td>-0.231458</td>\n      <td>-0.253843</td>\n      <td>-0.003732</td>\n      <td>-0.064550</td>\n      <td>0.201424</td>\n    </tr>\n    <tr>\n      <th>駅前に駐車場が少ない、不便</th>\n      <td>1.226444e-01</td>\n      <td>0.017410</td>\n      <td>0.509561</td>\n      <td>0.516643</td>\n      <td>-0.314527</td>\n      <td>-0.003270</td>\n      <td>-0.066299</td>\n      <td>0.261483</td>\n    </tr>\n  </tbody>\n</table>\n<p>86 rows × 8 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "pd.DataFrame(X,index=data['コメント'])"
   ]
  },
  {
   "source": [
    "LSI（潜在的意味索引）では、トピックという文書と単語の間に存在する抽象的な概念を導入します。 各文書の BOW あるいは TF-IDF ベクトルを行とする文書数×単語数の行列を特異値分解し、文書数×トピック数に次元削減します。 以下は文章 a ～ d の4つの TF-IDF ベクトルに LSI を適用した場合の図です。\n",
    "\n",
    "https://www.ogis-ri.co.jp/otc/hiroba/technical/similar-document-search/part1.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### コサイン類似度\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1.   0.   0.   0.   0.2  0.   0.   0.   0.17 0.   0.   0.   0.   0.\n  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n  0.   0.   0.   0.13 0.   0.   0.   0.   0.   0.   0.18 0.   0.   0.\n  0.   0.14 0.   0.   0.   0.16 0.   0.12 0.   0.   0.   0.   0.11 0.1\n  0.   0.   0.   0.   0.   0.   0.09 0.   0.   0.16 0.13 0.   0.   0.\n  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n  0.   0.18]]\n"
     ]
    }
   ],
   "source": [
    " from sklearn.metrics.pairwise import cosine_similarity\n",
    "print(cosine_similarity(model_tfidf[0:1],model_tfidf))"
   ]
  },
  {
   "source": [
    "## 単語分散表現\n",
    "\n",
    "文書中の単語出現数を元に文書ベクトルを導出していましたが、ここからは単語の持つ意味的な情報を用いる手法として、単語の分散表現について説明します。 単語の分散表現では単語を多次元空間上の座標にマッピングすることで、単語同士の類似度を比較したり、加減算したりすることができるようになります。「王」－「男」＋「女」≒「女王」という例が有名です。\n",
    "\n",
    "\n",
    "単語の分散表現の獲得方法は様々な手法が紹介されています。手法の皮切りとして2013年に登場した Word2Vec*2 は 同じ文脈で登場する単語は似た意味を持つという分布仮説をベースとしています。 以下は Word2Vec で実装された CBoW(Continuous Bag of words) の動作イメージです。”Yes We Can” という文章があったとして、周辺単語（”Yes”, “Can”）から注目する単語（”We”）を予測するモデルになります。\n",
    "\n",
    "### 単語ベクトル\n",
    "\n",
    "\n",
    "Doc と Span も同様に vector 属性があり、保持する Token の単語ベクトルの平均を返す実装となっています。\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "doc = nlp('スポーツ')\n",
    "doc.vector.shape"
   ]
  },
  {
   "source": [
    "## コースワーク\n",
    "\n",
    "\n",
    "今回のアンケートでは、自由形式のコメントと満足度を同時に回答するようになっていたため、満 足度の高いキーワードを抽出できました。また、コメント文をベクトル化することで、コメント間 の類似度が求められることも見えてきました。\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "\n",
    "**演習（文書分類）**\n",
    "\n",
    "満足度は予測できるのでしょうか?\n",
    "\n",
    "</div>\n",
    "\n",
    "これは、エントリーシートから(採用後の)満足度は予想できるのでしょうか?と同じ質問になります。\n",
    "皆さんは AI がエントリーシートを判定しているという噂を聞いたことがありますね。\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "\n",
    "**演習（エントリシート）**\n",
    "\n",
    "企業がどのように AI を活用して、エントリーシートを分析しているか\n",
    "考察してみよう。\n",
    "\n",
    "</div>\n",
    "\n",
    "今まで学んできた知識を総動員して、もし足りなかったら追加で調査して考えてみましょう。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}