{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 機械学習とクラス分類問題\n",
    "\n",
    "**機械学習 (machine learning)** とは、与えられた問題に対して、コンピュータ自身が学習し、学習結果を活かした問題解決を行うしくみのことです。人工知能 (artificial inteligence) を実現する手段として活用されています。\n",
    "\n",
    "今回は、クラス分類問題をとりあげ、いよいよ本格的な機械学習の世界に足を踏み入れていきます。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "try:\n",
    "    import japanize_matplotlib #matplotlibの日本語化  \n",
    "except ModuleNotFoundError:\n",
    "    !pip install japanize_matplotlib\n",
    "    import japanize_matplotlib \n",
    "sns.set(font=\"IPAexGothic\") #日本語フォント設定"
   ]
  },
  {
   "source": [
    "## 学習と機械学習\n",
    "\n",
    "ニュートンは、リンゴが落ちるのを見て、万有引力の法則を発見しました。\n",
    "もう少し正確に書くと、いろんな現象の観察結果と微積分を使って、「$F ∼ Mm/r^2$ としか思えない」という理由を示しています。\n",
    "\n",
    "<img src=\"http://ktymtskz.my.coocan.jp/S/physic/P/p88.jpg\" width=\"50%\" />\n",
    "\n",
    "発見された万有引力の法則は、数理モデルとして記述されて、\n",
    "これから発生する事象（未来）を予想できるようになります。\n",
    "\n",
    "__数理モデル__\n",
    "$$\n",
    "F ∼ Mm/r^2\n",
    "$$\n",
    "\n",
    "ニュートンが万有引力の法則を発見に至ったプロセスは興味深いものです。このプロセスをアルゴリズム化して、コンピュータが法則を発見し、モデル化する手法が機械学習です。\n",
    "\n",
    "__種類__:\n",
    "\n",
    "* 教師なし学習 (K-means法, PCAなど)\n",
    "* 教師あり学習 (線形回帰, ロジスティック回帰、決定木、サポートベクターマシン)\n",
    "* 強化学習 (Q-Learning)\n",
    "\n",
    "実は、前回までに学んだK-means法は教師なし学習、線形回帰は教師あり学習と分類され、機械学習アルゴリズムの一種でした。人工知能の基礎となる機械学習といっても、身構えなくてはならないほど難しいものではありません。\n",
    "\n",
    "### 教師あり学習\n",
    "\n",
    "教師あり学習は、問題と答えをコンピュータに与えることで予測モデルを学習させる方法です。\n",
    "事前に、「特徴を表すデータ」と答えである「目的データ」が必要です。 \n",
    "\n",
    "説明のため、これまでに作成してきた身長体重データセットを思い出してください。\n",
    "\n",
    "* **説明変数**: 特徴を表すデータとして、「身長」と「体重」が与えられる \n",
    "* **目的変数**: 目的データとして、「職業」が与えられる\n",
    "\n",
    "__学習__\n",
    "\n",
    "機械学習とは、説明変数と目的変数の大量のデータセットを与え、そこから目的変数を予測するモデルを作成することです。\n",
    "\n",
    "![ml_fit-fs8.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/57754/e14ceec0-fb4c-93b6-5273-658eba03f818.png)\n",
    "\n",
    "\n",
    "__予測__ \u0016 \n",
    "\n",
    "予測モデルに未知のデータを与えると、目的データが出力されます。\n",
    "\n",
    "\n",
    "![model_predict_X-fs8.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/57754/a5454677-a908-8ef2-d8e5-551b322dd097.png)\n",
    "\n",
    "目的データの種類によって、回帰問題と分類問題に分けられる。 \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "回帰と分類\n",
    "\n",
    "* **回帰問題**: 数値を予測すること\n",
    "* **クラス分類問題**: 職業などのカテゴリを予測すること\n",
    "\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### クラス分類\n",
    "\n",
    "クラス分類は、カテゴリデータを予測することです。カテゴリの数が２つなら２クラス分類、それ以上なら多クラス分類と呼ばれます。\n",
    "\n",
    "クラス分類が重要なのは、画像認識など興味深いアプリケーションが作れる点にあります。\n",
    "例えば、画像を多次元データとして説明変数、そのラベルを目的変数として学習させると、\n",
    "画像認識が可能になります。後半では、簡単な画像認識を少しだけ学びます。\n",
    "\n",
    "![ml-image-fs8.png](https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/57754/49804ec0-fca7-ab8b-b832-426db4f96d64.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 回帰からクラス分類へ\n",
    "\n",
    "ロジスティック回帰は、線形回帰のバリエーションです。\n",
    "ロジスティック「回帰」と、回帰がついていますが、クラス分類アルゴリズムです。\n",
    "回帰からクラス分類の原理を理解していきましょう。\n",
    "\n",
    "原理: 線形回帰の予測モデルに、シグモイド関数([ロジスティック関数](http://kenichia.hatenablog.com/entry/2017/03/04/122551))を組み合わせることで、カテゴリー値に変換します。\n",
    "\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Let's try\n",
    "\n",
    "シグモイド関数をmatplotlibで描画してみよう\n",
    "\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x139a92e50>]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"251.669687pt\" version=\"1.1\" viewBox=\"0 0 375.462969 251.669687\" width=\"375.462969pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-03-23T17:46:47.799564</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 251.669687 \nL 375.462969 251.669687 \nL 375.462969 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.462969 224.64 \nL 368.262969 224.64 \nL 368.262969 7.2 \nL 33.462969 7.2 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 48.681151 224.64 \nL 48.681151 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_1\">\n      <!-- −10.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(33.104979 242.379687)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 6.5 34.71875 \nL 61.28125 34.71875 \nL 61.28125 29 \nL 6.5 29 \nz\n\" id=\"IPAexGothic-8722\"/>\n        <path d=\"M 38.484375 0.984375 \nL 29.6875 0.984375 \nL 29.6875 64.109375 \nQ 21.4375 61.28125 12.3125 59.328125 \nL 10.6875 66.109375 \nQ 23.734375 69.390625 32.90625 73.921875 \nL 38.484375 73.921875 \nz\n\" id=\"IPAexGothic-49\"/>\n        <path d=\"M 31.84375 73.828125 \nQ 45.015625 73.828125 52.09375 61.625 \nQ 57.71875 51.953125 57.71875 36.625 \nQ 57.71875 21.4375 52.09375 11.578125 \nQ 45.125 -0.484375 31.5 -0.484375 \nQ 17.921875 -0.484375 10.9375 11.578125 \nQ 5.328125 21.4375 5.328125 36.71875 \nQ 5.328125 58.015625 15.625 67.71875 \nQ 22.171875 73.828125 31.84375 73.828125 \nz\nM 31.5 66.65625 \nQ 23.6875 66.65625 19.1875 58.734375 \nQ 14.59375 50.734375 14.59375 36.625 \nQ 14.59375 22.75 19.09375 14.796875 \nQ 23.640625 6.984375 31.5 6.984375 \nQ 40.921875 6.984375 45.453125 18.015625 \nQ 48.4375 25.34375 48.4375 37.109375 \nQ 48.4375 50.875 43.84375 58.734375 \nQ 39.203125 66.65625 31.5 66.65625 \nz\n\" id=\"IPAexGothic-48\"/>\n        <path d=\"M 18.5 0.984375 \nL 7.71875 0.984375 \nL 7.71875 11.765625 \nL 18.5 11.765625 \nz\n\" id=\"IPAexGothic-46\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-8722\"/>\n       <use x=\"67.822266\" xlink:href=\"#IPAexGothic-49\"/>\n       <use x=\"130.810547\" xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"193.798828\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"220.214844\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 86.917788 224.64 \nL 86.917788 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_2\">\n      <!-- −7.5 -->\n      <g style=\"fill:#262626;\" transform=\"translate(74.805757 242.379687)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 56.203125 66.609375 \nQ 34.96875 32.90625 27.78125 0.984375 \nL 17.671875 0.984375 \nQ 24.703125 28.65625 46.09375 64.5 \nL 6.6875 64.5 \nL 6.6875 72.40625 \nL 56.203125 72.40625 \nz\n\" id=\"IPAexGothic-55\"/>\n        <path d=\"M 18.40625 40.671875 \nQ 25.53125 46.296875 33.9375 46.296875 \nQ 44 46.296875 50.640625 39.5 \nQ 56.84375 33.015625 56.84375 23.390625 \nQ 56.84375 14.65625 51.515625 8.015625 \nQ 44.828125 -0.484375 31.734375 -0.484375 \nQ 14.984375 -0.484375 7.328125 12.25 \nL 14.65625 16.0625 \nQ 20.453125 6.78125 31.453125 6.78125 \nQ 38.53125 6.78125 43.265625 11.1875 \nQ 48.140625 15.828125 48.140625 23.484375 \nQ 48.140625 30.71875 43.84375 35.015625 \nQ 39.359375 39.5 32.125 39.5 \nQ 21.96875 39.5 16.75 31.6875 \nL 9.234375 32.671875 \nL 13.8125 72.40625 \nL 53.21875 72.40625 \nL 53.21875 64.890625 \nL 20.953125 64.890625 \nL 17.71875 40.671875 \nz\n\" id=\"IPAexGothic-53\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-8722\"/>\n       <use x=\"67.822266\" xlink:href=\"#IPAexGothic-55\"/>\n       <use x=\"130.810547\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"157.226562\" xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 125.154426 224.64 \nL 125.154426 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_3\">\n      <!-- −5.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(113.042395 242.379687)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-8722\"/>\n       <use x=\"67.822266\" xlink:href=\"#IPAexGothic-53\"/>\n       <use x=\"130.810547\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"157.226562\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 163.391064 224.64 \nL 163.391064 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_4\">\n      <!-- −2.5 -->\n      <g style=\"fill:#262626;\" transform=\"translate(151.279033 242.379687)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 57.171875 0.984375 \nL 6.984375 0.984375 \nL 6.984375 9.28125 \nQ 12.890625 23.046875 29.59375 34.421875 \nL 32.375 36.28125 \nQ 40.921875 42.140625 43.609375 45.40625 \nQ 46.6875 49.265625 46.6875 53.8125 \nQ 46.6875 58.9375 43.0625 62.546875 \nQ 39.0625 66.546875 32.5625 66.546875 \nQ 19.53125 66.546875 15.484375 52 \nL 7.765625 54.78125 \nQ 13.328125 73.828125 33.0625 73.828125 \nQ 43.84375 73.828125 50.25 67.4375 \nQ 55.859375 61.671875 55.859375 53.515625 \nQ 55.859375 47.46875 52.25 42.53125 \nQ 48.921875 37.75 36.96875 30.28125 \nL 34.859375 29 \nQ 19.625 19.578125 15.28125 8.890625 \nL 57.171875 8.890625 \nz\n\" id=\"IPAexGothic-50\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-8722\"/>\n       <use x=\"67.822266\" xlink:href=\"#IPAexGothic-50\"/>\n       <use x=\"130.810547\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"157.226562\" xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 201.627702 224.64 \nL 201.627702 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_5\">\n      <!-- 0.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(193.246217 242.379687)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 239.864339 224.64 \nL 239.864339 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2.5 -->\n      <g style=\"fill:#262626;\" transform=\"translate(231.482855 242.379687)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-50\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 278.100977 224.64 \nL 278.100977 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_7\">\n      <!-- 5.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(269.719493 242.379687)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-53\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 316.337615 224.64 \nL 316.337615 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_8\">\n      <!-- 7.5 -->\n      <g style=\"fill:#262626;\" transform=\"translate(307.95613 242.379687)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-55\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 354.574252 224.64 \nL 354.574252 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(342.728627 242.379687)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-49\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"125.976562\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"152.392578\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 33.462969 214.765338 \nL 368.262969 214.765338 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 218.885182)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 33.462969 175.227014 \nL 368.262969 175.227014 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 179.346858)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 33.462969 135.68869 \nL 368.262969 135.68869 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 139.808534)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 59.578125 18.109375 \nL 47.796875 18.109375 \nL 47.796875 0.984375 \nL 39.796875 0.984375 \nL 39.796875 18.109375 \nL 3.078125 18.109375 \nL 3.078125 26.125 \nL 38.375 73.09375 \nL 47.796875 73.09375 \nL 47.796875 25.53125 \nL 59.578125 25.53125 \nz\nM 40.28125 64.203125 \nL 39.984375 64.203125 \nQ 35.59375 57.125 31.296875 51.3125 \nL 11.859375 25.53125 \nL 39.796875 25.53125 \nL 39.796875 49.125 \nQ 39.796875 54.390625 40.28125 64.203125 \nz\n\" id=\"IPAexGothic-52\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 33.462969 96.150366 \nL 368.262969 96.150366 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.6 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 100.27021)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 16.5 36.375 \nQ 23.578125 46.578125 34.90625 46.578125 \nQ 45.40625 46.578125 51.8125 39.265625 \nQ 57.421875 32.90625 57.421875 23.78125 \nQ 57.421875 13.8125 51.125 6.78125 \nQ 44.578125 -0.484375 34.03125 -0.484375 \nQ 21.484375 -0.484375 14.40625 9.078125 \nQ 7.515625 18.40625 7.515625 34.8125 \nQ 7.515625 53.515625 15.828125 64.203125 \nQ 23.34375 73.828125 35.5 73.828125 \nQ 49.859375 73.828125 56.390625 62.890625 \nL 49.21875 58.984375 \nQ 45.21875 66.65625 35.9375 66.65625 \nQ 17.484375 66.65625 16.109375 36.375 \nz\nM 33.453125 39.796875 \nQ 26.3125 39.796875 21.625 34.46875 \nQ 17.4375 29.6875 17.4375 24.078125 \nQ 17.4375 18.0625 21.140625 13.1875 \nQ 26.125 6.6875 33.734375 6.6875 \nQ 41.703125 6.6875 45.953125 13.1875 \nQ 48.828125 17.625 48.828125 23.484375 \nQ 48.828125 30.375 45.015625 34.8125 \nQ 40.625 39.796875 33.453125 39.796875 \nz\n\" id=\"IPAexGothic-54\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 33.462969 56.612042 \nL 368.262969 56.612042 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.8 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 60.731886)scale(0.11 -0.11)\">\n       <defs>\n        <path d=\"M 39.703125 37.890625 \nQ 57.8125 31.734375 57.8125 18.703125 \nQ 57.8125 8.453125 48.4375 3.078125 \nQ 41.609375 -0.875 31.5 -0.875 \nQ 21.34375 -0.875 14.5 3.078125 \nQ 5.421875 8.296875 5.421875 18.40625 \nQ 5.421875 31.0625 22.015625 37.203125 \nL 22.015625 37.5 \nQ 7.515625 42.71875 7.515625 54.828125 \nQ 7.515625 64.0625 15.328125 69.625 \nQ 21.96875 74.3125 31.546875 74.3125 \nQ 42.234375 74.3125 48.921875 68.796875 \nQ 55.515625 63.578125 55.515625 55.71875 \nQ 55.515625 42.28125 39.703125 38.1875 \nz\nM 31.59375 41.015625 \nQ 46.828125 44.625 46.828125 55.125 \nQ 46.828125 61.1875 41.796875 64.84375 \nQ 37.703125 67.921875 31.5 67.921875 \nQ 25.09375 67.921875 20.796875 64.5 \nQ 16.40625 60.890625 16.40625 55.03125 \nQ 16.40625 49.21875 21.09375 45.703125 \nQ 23.34375 43.890625 26.90625 42.53125 \nQ 31 40.875 31.59375 41.015625 \nz\nM 30.90625 34.515625 \nQ 14.40625 30.171875 14.40625 19 \nQ 14.40625 12.109375 20.515625 8.6875 \nQ 25.09375 6.109375 31.390625 6.109375 \nQ 40.234375 6.109375 45.015625 10.890625 \nQ 48.53125 14.40625 48.53125 19.53125 \nQ 48.53125 24.90625 43.65625 28.90625 \nQ 40.765625 31.15625 36.71875 32.8125 \nQ 31.984375 34.71875 30.90625 34.515625 \nz\n\" id=\"IPAexGothic-56\"/>\n       </defs>\n       <use xlink:href=\"#IPAexGothic-48\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 33.462969 17.073718 \nL 368.262969 17.073718 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.0 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 21.193561)scale(0.11 -0.11)\">\n       <use xlink:href=\"#IPAexGothic-49\"/>\n       <use x=\"62.988281\" xlink:href=\"#IPAexGothic-46\"/>\n       <use x=\"89.404297\" xlink:href=\"#IPAexGothic-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pc3c540e9d1)\" d=\"M 48.681151 214.756364 \nL 89.976719 214.63188 \nL 105.271374 214.402982 \nL 115.977633 214.036995 \nL 123.624961 213.567366 \nL 129.742823 212.983485 \nL 134.331219 212.367648 \nL 138.919616 211.542471 \nL 143.508012 210.439595 \nL 146.566943 209.507336 \nL 149.625874 208.380796 \nL 152.684805 207.022603 \nL 155.743736 205.389641 \nL 158.802667 203.432829 \nL 161.861598 201.097252 \nL 164.920529 198.322793 \nL 167.97946 195.045503 \nL 171.038391 191.19992 \nL 174.097322 186.722572 \nL 177.156253 181.556781 \nL 180.215184 175.658751 \nL 183.274115 169.004628 \nL 186.333046 161.597873 \nL 189.391977 153.475891 \nL 192.450908 144.714559 \nL 197.039305 130.63619 \nL 210.804495 87.124497 \nL 213.863426 78.363165 \nL 216.922357 70.241183 \nL 219.981288 62.834428 \nL 223.040219 56.180305 \nL 226.09915 50.282275 \nL 229.158081 45.116485 \nL 232.217012 40.639137 \nL 235.275943 36.793554 \nL 238.334874 33.516263 \nL 241.393805 30.741804 \nL 244.452736 28.406227 \nL 247.511667 26.449415 \nL 250.570598 24.816453 \nL 253.629529 23.458261 \nL 256.68846 22.331721 \nL 259.747391 21.399462 \nL 264.335787 20.296585 \nL 268.924184 19.471408 \nL 273.51258 18.855571 \nL 279.630442 18.27169 \nL 287.27777 17.802061 \nL 296.454563 17.474107 \nL 310.219753 17.2367 \nL 333.161735 17.110107 \nL 353.044787 17.083636 \nL 353.044787 17.083636 \n\" style=\"fill:none;stroke:#4c72b0;stroke-linecap:round;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.462969 224.64 \nL 33.462969 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.262969 224.64 \nL 368.262969 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.462969 224.64 \nL 368.262969 224.64 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.462969 7.2 \nL 368.262969 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc3c540e9d1\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"33.462969\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from math import e\n",
    "\n",
    "x = np.arange(-10, 10, 0.1)\n",
    "y = 1 / (1 + e**-x)\n",
    "\n",
    "plt.plot(x, y)\n"
   ]
  },
  {
   "source": [
    "\n",
    "__線形回帰(前回)__\n",
    "\n",
    "$$\n",
    "y = a_1 x_1+a_2 x_2 + a_n x_n + b\n",
    "$$\n",
    "\n",
    "__ロジスティック回帰__\n",
    "\n",
    "目的変数は、確率であるため$𝑝$とおきます。\n",
    "すると、$𝑥_𝑖$ がどんな値をとっても目的変数$𝑝$が$0$から$1$までの範囲に収まります。\n",
    "\n",
    "$$\n",
    "p = \\frac{1}{1 + e^{a_1 x_1+a_2 x_2 + a_n x_n + b}}\n",
    "$$\n",
    "\n",
    "少し式を変形してみましょう。\n",
    "\n",
    "$$\n",
    "\\frac{p}{1-p} = e^{a_1 x_1+a_2 x_2 + a_n x_n + b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "log{\\frac{p}{1-p}} = a_1 x_1+a_2 x_2 + a_n x_n + b = l\n",
    "$$\n",
    "\n",
    "これで、線形回帰と同じように、\n",
    "最小二乗法を用いて偏回帰係数$a_i$が求められることがわかると思います。\n",
    "\n",
    "なお、$l$のことをロジットと呼び、ロジットの対数をとると、オッズ比が出てきます。\n",
    "(オッズ比は、ある事象が発生する確率と発生しない確率の比になっています。)\n",
    "\n",
    "$$\n",
    "e^{l} = \\frac{p}{1-p}\n",
    "$$\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "２クラス分類問題と多クラス分類問題\n",
    "\n",
    "数学的に扱いやすいため、２クラス分類問題と多クラス分類問題は区別されています。\n",
    "上記の説明は、２クラス分類のケースですが、\n",
    "ロジスティック回帰は多クラス分類に拡張されています。\n",
    "興味があるときは、多クラスロジスティック回帰の原理も調べてみましょう。\n",
    "\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## ２クラス分類問題\n",
    "\n",
    "乳がんデータセットを用いて、２クラス分類問題として、乳がんの良性・悪性を判定しましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   良性   平均半径   平均感触   平均周囲長    平均面積    平均平滑性    平均密集度    平均凹部     平均凹点  \\\n",
       "0   0  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710   \n",
       "1   0  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n",
       "2   0  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n",
       "3   0  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n",
       "4   0  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n",
       "\n",
       "    平均対称性  ...   最悪半径   最悪感触   最悪周囲長  最悪半径.1   最悪平滑さ   最悪密集度    最悪凹部    最悪凹点  \\\n",
       "0  0.2419  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.1812  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.2069  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.2597  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.1809  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "    最悪対称性  最悪フラクタル次元  \n",
       "0  0.4601    0.11890  \n",
       "1  0.2750    0.08902  \n",
       "2  0.3613    0.08758  \n",
       "3  0.6638    0.17300  \n",
       "4  0.2364    0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>良性</th>\n      <th>平均半径</th>\n      <th>平均感触</th>\n      <th>平均周囲長</th>\n      <th>平均面積</th>\n      <th>平均平滑性</th>\n      <th>平均密集度</th>\n      <th>平均凹部</th>\n      <th>平均凹点</th>\n      <th>平均対称性</th>\n      <th>...</th>\n      <th>最悪半径</th>\n      <th>最悪感触</th>\n      <th>最悪周囲長</th>\n      <th>最悪半径.1</th>\n      <th>最悪平滑さ</th>\n      <th>最悪密集度</th>\n      <th>最悪凹部</th>\n      <th>最悪凹点</th>\n      <th>最悪対称性</th>\n      <th>最悪フラクタル次元</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('cancer_ja.csv')\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "乳がんのデータセットは、クラスタリングと主成分分析を思い出してください。\n",
    "\n",
    "### 学習モデル\n",
    "\n",
    "まず、とりあえずロジスティック回帰モデルを学習してみましょう。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "source": [
    "重回帰のときと同じく、２つの説明変数にしてみます。\n",
    "\n",
    "ここでは、適当にふたつの`平均半径`と`平均感触`を選んでいます。\n",
    "他の説明変数に変えてみてください。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X = data[['平均半径', '平均感触']]\n",
    "y = data['良性']\n",
    "model = LogisticRegression()\n",
    "\n",
    "# 学習の実行\n",
    "model.fit(X, y)"
   ]
  },
  {
   "source": [
    "学習したモデルが予測するのは、`predict`を使います。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.predict([(20, 18)])"
   ]
  },
  {
   "source": [
    "入力に対して、予測された良性/悪性が出力されました。\n",
    "モデルの学習はできたようです。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Let's try\n",
    "\n",
    "入力を変更してどのように予測されるか調べてみよう。\n",
    "また、予測間違いを起こすデータも調べてみよう。\n",
    "\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     正解  予測\n",
       "0     0   0\n",
       "1     0   0\n",
       "2     0   0\n",
       "3     0   1\n",
       "4     0   0\n",
       "..   ..  ..\n",
       "564   0   0\n",
       "565   0   0\n",
       "566   0   0\n",
       "567   0   0\n",
       "568   1   1\n",
       "\n",
       "[569 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>正解</th>\n      <th>予測</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>564</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>565</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>568</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>569 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y_pred = model.predict(X)\n",
    "pd.DataFrame({'正解': y, '予測': y_pred})"
   ]
  },
  {
   "source": [
    "### 正解率\n",
    "\n",
    "ロジスティック回帰を始め、機械学習によって予測されるモデルは基本的に確率的なモデルです。 \n",
    "100%正解ということはまずありません。 \n",
    "予測されたモデルがどの程度、正解率なのか調べる必要があります。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Accuracy: 正解率\n",
    "\n",
    "正解率を定量的に図る指標\n",
    "\n",
    "$$\n",
    "\\frac{TF+TN}{TP+FP+FN+TN}\n",
    "$$\n",
    "\n",
    "* TF(True Positive): 例. 良性かつ良性と予想される\n",
    "* FN(False Negative, 偽陰性): 悪性であるが、良性と予想される\n",
    "* FP(False Positive, 偽陽性): 良性であるが、悪性と予想される\n",
    "* TN(True Negative): 悪性かつ悪性と判定される\n",
    "\n",
    "こちらの解説に詳しい: https://qiita.com/FukuharaYohei/items/be89a99c53586fa4e2e4\n",
    "\n",
    "</div>\n",
    "\n",
    "sklearn では、正解率を計算するための関数(メソッド）も当然、用意されています。\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8910369068541301"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "source": [
    "### オッズ比の分析\n",
    "\n",
    "説明変数の各々が目的変数に及ぼす影響度を表わす偏係数は`.coef_`で習得できるので、\n",
    "学習済みモデルの各変数のオッズ比を取得します。\n",
    "\n",
    "```\n",
    "odds_ratio = np.exp(model.coef_)\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "print('係数', model.coef_)\n",
    "print('オッズ比:', np.exp(model.coef_))\n",
    "pd.DataFrame(np.exp(model.coef_).T,\n",
    "             index = [X.columns.values],\n",
    "             columns = ['オッズ比'])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "係数 [[-1.0462619  -0.21688595]]\nオッズ比: [[0.3512483  0.80502177]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          オッズ比\n",
       "平均半径  0.351248\n",
       "平均感触  0.805022"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>オッズ比</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>平均半径</th>\n      <td>0.351248</td>\n    </tr>\n    <tr>\n      <th>平均感触</th>\n      <td>0.805022</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "source": [
    "## ホールドアウト法\n",
    "\n",
    "人工知能では、過去に学習したデータではなく、\n",
    "未来の**未知のデータ**に対する予測精度が重要になります。\n",
    "\n",
    "**ホールドアウト法**は、全データを訓練データとテストデータに分割することで、モデルの精度を評価する方法です。一部のデータを未知のデータとすることで、未知のデータに対する精度が測定できるようになります。\n",
    "\n",
    "* 訓練データ: モデルを学習するためのデータ\n",
    "* テストデータ: モデルを評価するためのデータ\n",
    "\n",
    "sklearn には、ランダムにデータを訓練データとテストデータに分割する関数`train_test_split()`が用意されています。通常は、この関数を使います。\n",
    "\n",
    "__訓練データとテストデータに分割__\n",
    "\n",
    "* `test_size`: 訓練用(60%),テスト用(30%)\n",
    "* `random_state=0`: 乱数の生成を固定し、毎回同じ乱数で分割させる"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "訓練データ数: 398\nテストデータ数: 171\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('訓練データ数:', len(X_train))\n",
    "print('テストデータ数:', len(X_test))\n"
   ]
  },
  {
   "source": [
    "学習は、**訓練データ**に対してのみ行います。（テストデータに対しても学習してしまうのは、機械学習的にはチートです。）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# 学習の実行\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "テストデータを使って、モデルを評価していきます。\n",
    "\n",
    "__テストデータからまとめて予測する__\n",
    "\n",
    "* `y_test`: （未知データの）正解\n",
    "* `y_pred:`: モデルから予測値\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     正解  予測\n",
       "512   0   1\n",
       "457   1   1\n",
       "439   1   1\n",
       "298   1   1\n",
       "37    1   1\n",
       "..   ..  ..\n",
       "7     0   1\n",
       "408   0   0\n",
       "523   1   1\n",
       "361   1   1\n",
       "553   1   1\n",
       "\n",
       "[171 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>正解</th>\n      <th>予測</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>512</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>457</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>439</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>408</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>523</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>171 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "pd.DataFrame({'正解': y_test, '予測': y_pred})"
   ]
  },
  {
   "source": [
    "正解率は、訓練データとテストデータに対して、それぞれ算出します。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正解率(train) 0.8894472361809045\n正解率(test) 0.9064327485380117\n"
     ]
    }
   ],
   "source": [
    "print('正解率(train)', model.score(X_train, y_train))\n",
    "print('正解率(test)', model.score(X_test, y_test))"
   ]
  },
  {
   "source": [
    "正解率(test)は、訓練データに含まれていない未知データに対する正解率なので、\n",
    "**汎化性能**を表しています。\n",
    "\n",
    "正解率(train)を調べるのも重要です。\n",
    "機械学習によくあることですが、\n",
    "訓練データへの適合しすぎてしまう**過学習(overfitting)**が発生していないか、\n",
    "確認することができます。\n",
    "正解率(train)が正解率(test)より高すぎる場合は、過学習の危険性があります。\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "過学習\n",
    "\n",
    "訓練データに特化して学習しすぎてしまうこと。\n",
    "訓練データの正解率がテストデータより明らかに高い場合は、過学習を疑いましょう。\n",
    "\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 多クラスロジスティック回帰\n",
    "\n",
    "次は、ロジスティック回帰モデルによる多クラス分類をしてみましょう。\n",
    "\n",
    "今回は、身長体重データセットから職業を予測するモデルを作ってみます。\n",
    "せっかくなので、学習済モデルを一旦ファイルに保存し、ロードしたモデルも正しく動作するか、\n",
    "検証してみます。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "データのサイズ (1535, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       名前     身長    体重 職業\n",
       "0   福井　優也  178.0  85.0  B\n",
       "1   九里　亜蓮  187.0  92.0  B\n",
       "2   加藤　拓也  176.0  88.0  B\n",
       "3  大瀬良　大地  187.0  93.0  B\n",
       "4    今村　猛  183.0  98.0  B"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>名前</th>\n      <th>身長</th>\n      <th>体重</th>\n      <th>職業</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>福井　優也</td>\n      <td>178.0</td>\n      <td>85.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>九里　亜蓮</td>\n      <td>187.0</td>\n      <td>92.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>加藤　拓也</td>\n      <td>176.0</td>\n      <td>88.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>大瀬良　大地</td>\n      <td>187.0</td>\n      <td>93.0</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>今村　猛</td>\n      <td>183.0</td>\n      <td>98.0</td>\n      <td>B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "data = pd.read_csv('bmi.csv')\n",
    "print('データのサイズ', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "source": [
    "### 学習\n",
    "\n",
    "`身長`と`体重`を説明変数、`職業`を目的変数にしてロジスティック回帰モデルを作成します。\n",
    "多クラス分類であっても、sklearnが適切に処理してくれるので、特に特別な設定は必要ありません。\n",
    "\n",
    "ホールドアウト法で訓練データとテストデータに分割するのを忘れないようにしましょう。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "訓練データ数: 1074\nテストデータ数: 461\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "X = data[['身長', '体重']]\n",
    "y = data['職業']\n",
    "\n",
    "# ホールドアウト法による訓練データとテストデータ\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print('訓練データ数:', len(X_train))\n",
    "print('テストデータ数:', len(X_test))\n",
    "\n",
    "# 学習の実行\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "source": [
    "学習したモデルが予測するのは、`predict`を使います。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     正解 予測\n",
       "1421  F  B\n",
       "1018  F  F\n",
       "651   B  B\n",
       "303   B  B\n",
       "1127  F  F"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>正解</th>\n      <th>予測</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1421</th>\n      <td>F</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>1018</th>\n      <td>F</td>\n      <td>F</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>B</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>303</th>\n      <td>B</td>\n      <td>B</td>\n    </tr>\n    <tr>\n      <th>1127</th>\n      <td>F</td>\n      <td>F</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "pd.DataFrame({'正解': y_test, '予測':y_pred}).head()"
   ]
  },
  {
   "source": [
    "正解率も評価しておきましょう。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "正解率(train) 0.8305400372439479\n正解率(test) 0.8524945770065075\n"
     ]
    }
   ],
   "source": [
    "print('正解率(train)', model.score(X_train, y_train))\n",
    "print('正解率(test)', model.score(X_test, y_test))"
   ]
  },
  {
   "source": [
    "## クラス分類アルゴリズム\n",
    "\n",
    "クラス分類アルゴリズムは、ロジスティック回帰以外あります。\n",
    "sklearn から簡単に試せるものもあります。\n",
    "\n",
    "__決定木__: `sklearn.tree.DecisionTreeClassifier`\n",
    "\n",
    "決定木は、条件分岐によってグループを分割して分類する手法です。その際にグループがなるべく同じような属性で構成されるように分割します。\n",
    "\n",
    "__ランダムフォレスト__: `sklearn.ensemble.RandomForestClassifier`\n",
    "\n",
    "ランダムフォレストとは、分類や回帰に使える機械学習の手法です。決定木をたくさん作って多数決する（または平均を取る）ような手法です。ランダムフォレストは大量のデータを必要としますが、精度の高い予測/分類を行えるという特徴があります。\n",
    "\n",
    "__サポートベクターマシン（SVC)__: `sklearn.svm.LinearSVC`\n",
    "\n",
    "サポートベクターマシンは、パターン認識モデルの一つで、線形入力素子を利用して2クラスのパターン識別器を構成する手法です。2つのグループ間の最も距離の離れた箇所（最大マージン）を見つけ出し、その真ん中に識別の線を引きます。\n",
    "\n",
    "__ナイーブベイズ分類器__: `sklearn.naive_bayes.GaussianNB`\n",
    "\n",
    "ナイーブベイズ分類器は特徴間に強い（ナイーブな）独立性を仮定した上でベイズの定理を使う、確率に基づいたアルゴリズムです。\n",
    "\n",
    "__多層パーセプトロン(MLP)__: `sklearn.neural_network.MLPClassifier`\n",
    "\n",
    "人間の脳（ニューロン）の数理モデルに基づくアルゴリズムです。深層学習に用いられています。詳しい原理は、授業の後半で扱います。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## コースワーク\n",
    "\n",
    "<div class=\"admonition tip\">\n",
    "\n",
    "**例題（２クラス分類問題）**\n",
    "\n",
    "乳がんのデータをホールドアウト法で訓練データとテストデータ(7:3)に分割し、\n",
    "良性か悪性か判定する予測モデルを作成してみよう。\n",
    "\n",
    "1. ロジスティック回帰\n",
    "2. 決定木\n",
    "3. ランダムフォレスト\n",
    "4. サポートベクターマシン\n",
    "5. ナイーブベイズ\n",
    "6. 多層パーセプトロン(MLP)\n",
    "\n",
    "説明変数は、各アルゴリズムに適したものを選んで構いません。\n",
    "テストデータに対する正解率で比較してみましょう。\n",
    "\n",
    "</div>\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}